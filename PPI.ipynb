{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "bio_dataset = pd.read_excel('BioDataset.xlsx', sheet_name='vzs3zr1726592551_s_list.mitab_p')\n",
    "labeled_interactions = pd.read_csv('labeled_interactions.csv')\n",
    "labeled_interactions_type = pd.read_csv('labeled_interactionsTYPE.csv')\n",
    "\n",
    "# Merge datasets based on protein pairs\n",
    "merged = pd.merge(labeled_interactions, labeled_interactions_type, on=['protein_1', 'protein_2', 'sequence_1', 'sequence_2', 'label'])\n",
    "\n",
    "# Add relevant columns from BioDataset based on proteins\n",
    "bio_dataset_filtered = bio_dataset[['Unnamed: 21', 'Unnamed: 22']]\n",
    "bio_dataset_filtered.columns = ['sequence_1_bio', 'sequence_2_bio']\n",
    "\n",
    "merged['sequence_1'] = merged['sequence_1'].combine_first(bio_dataset_filtered['sequence_1_bio'])\n",
    "merged['sequence_2'] = merged['sequence_2'].combine_first(bio_dataset_filtered['sequence_2_bio'])\n",
    "\n",
    "# Check class distribution\n",
    "label_distribution = merged['label'].value_counts()\n",
    "print(\"Class Distribution:\\n\", label_distribution)\n",
    "\n",
    "# Prepare interaction type labels (convert to categorical)\n",
    "interaction_types = merged['interaction_type'].unique()\n",
    "interaction_type_dict = {t: i for i, t in enumerate(interaction_types)}\n",
    "merged['interaction_type_encoded'] = merged['interaction_type'].map(interaction_type_dict)\n",
    "y_type = to_categorical(merged['interaction_type_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and pad sequences\n",
    "tokenizer = Tokenizer()\n",
    "all_sequences = merged['sequence_1'].tolist() + merged['sequence_2'].tolist()\n",
    "tokenizer.fit_on_texts(all_sequences)\n",
    "\n",
    "max_seq_length = 500  # Adjust based on input data\n",
    "X_seq1 = pad_sequences(tokenizer.texts_to_sequences(merged['sequence_1']), maxlen=max_seq_length)\n",
    "X_seq2 = pad_sequences(tokenizer.texts_to_sequences(merged['sequence_2']), maxlen=max_seq_length)\n",
    "\n",
    "# Combine the padded sequences as input for NN\n",
    "X = np.hstack((X_seq1, X_seq2))\n",
    "\n",
    "# Encode labels for binary classification\n",
    "y_binary = merged['label']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train_binary, y_test_binary = train_test_split(X, y_binary, test_size=0.2, random_state=42)\n",
    "_, _, y_train_type, y_test_type = train_test_split(X, y_type, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check for overlapping sequences (data leakage)\n",
    "train_sequences = set(tuple(seq) for seq in X_train)\n",
    "test_sequences = set(tuple(seq) for seq in X_test)\n",
    "overlap = train_sequences.intersection(test_sequences)\n",
    "print(f'Number of overlapping sequences between train and test sets: {len(overlap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input\n",
    "input_layer = Input(shape=(2*max_seq_length,))\n",
    "\n",
    "# Shared embedding and LSTM layers\n",
    "x = Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=128, input_length=2*max_seq_length)(input_layer)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(32)(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "\n",
    "\n",
    "# Output for binary classification\n",
    "output_binary = Dense(1, activation='sigmoid', name='binary_output')(x)\n",
    "\n",
    "# Output for interaction type classification\n",
    "output_multiclass = Dense(len(interaction_types), activation='softmax', name='type_output')(x)\n",
    "\n",
    "# Define model\n",
    "model = Model(inputs=input_layer, outputs=[output_binary, output_multiclass])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss={'binary_output': 'binary_crossentropy', 'type_output': 'categorical_crossentropy'},\n",
    "              metrics={'binary_output': 'accuracy', 'type_output': 'accuracy'})\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, \n",
    "                    {'binary_output': y_train_binary, 'type_output': y_train_type},\n",
    "                    validation_data=(X_test, {'binary_output': y_test_binary, 'type_output': y_test_type}),\n",
    "                    epochs=20, \n",
    "                    batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training vs validation loss for both tasks\n",
    "plt.plot(history.history['loss'], label='Total Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Overall Loss Trends')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "loss, binary_loss, multiclass_loss, binary_acc, multiclass_acc = model.evaluate(\n",
    "    X_test, {'binary_output': y_test_binary, 'type_output': y_test_type}\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Binary Classification Accuracy: {binary_acc}')\n",
    "print(f'Multiclass Classification Accuracy: {multiclass_acc}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
